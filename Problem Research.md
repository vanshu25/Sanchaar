# Problem Research

* Sign Language is a communication language just like any other language which is used among deaf community. The dataset that we have used in our project is a complete set of gestures which are used in sign language and can be used by other normal people for better understanding of the sign language gestures.

* We can often see sign language interpreters at press conferences or other public address scenarios, standing on stage and conveying speakers’ messages using hand gestures and body movements. But sign language has no such formal presence in the hectic environment of contemporary video conferencing, where the platforms generally use audio cues to spotlight the person speaking at a given moment.

* We researched about the problem that specially abled people face and looked for datasets in order to get accurate results. Finally narrowed it down to using ASL and planned on making an extension to be used on Microsoft Teams that could be enabled for these people that acts as a translator.

* People with hearing impairments, or other conditions that make vocal speech difficult, number in the hundreds of millions, rely on the same common tech tools as the hearing population. But while emails and text chat are useful and of course very common now, they aren’t a replacement for face-to-face communication, and unfortunately there’s no easy way for signing to be turned into written or spoken words, so this remains a significant barrier.

* With the amount of video calls going on these days and likely for the rest of eternity, accessibility is being left behind — only some platforms offer automatic captioning, transcription, summaries, and certainly none recognize sign language. But with SANCHAAR EXTENSION people could sign normally and participate in a video call naturally rather than using the neglected chat function
